{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JQvn3ll9XSBa"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulmert89/dsBootcamp/blob/master/project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CzX6kBd7BMA",
        "colab_type": "text"
      },
      "source": [
        "# Project 3: Classification Project\n",
        "Data Set: [Twitter US Airline Sentiment](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) <br>\n",
        "*\\\"Analyze how travelers in February 2015 expressed their feelings on Twitter\\\"*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGvcHSrlJai",
        "colab_type": "text"
      },
      "source": [
        "# 0 - Introduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQr4a9jF6wGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fcca9a55-490c-43d9-be1f-6d5ea8ea421a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFq_SsQcDb1r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ce9e3a80-2696-4555-e02a-e39fb0796bb3"
      },
      "source": [
        "# let's gather the gang for the party:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# import warnings\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# specs of the party balloons\n",
        "title_font = {\"family\":\"serif\", \"weight\":\"bold\", \"color\":\"black\", \"size\":20}\n",
        "axis_font = {\"family\":\"sans\", \"weight\":\"normal\", \"color\":\"black\", \"size\":16}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaQMCMnH7jr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "ed0b2893-7348-449b-a636-fd42d6bc463f"
      },
      "source": [
        "# calling our honor guest:\n",
        "tweets = pd.read_csv(\"/content/drive/My Drive/MertColab/proje3/tweets.csv\")\n",
        "tweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCS0lHOJfInP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "1e7d25e0-8d6d-4632-9bb9-1418dd067a4d"
      },
      "source": [
        "# first, she introduces herself\n",
        "tweets.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14640 entries, 0 to 14639\n",
            "Data columns (total 15 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   tweet_id                      14640 non-null  int64  \n",
            " 1   airline_sentiment             14640 non-null  object \n",
            " 2   airline_sentiment_confidence  14640 non-null  float64\n",
            " 3   negativereason                9178 non-null   object \n",
            " 4   negativereason_confidence     10522 non-null  float64\n",
            " 5   airline                       14640 non-null  object \n",
            " 6   airline_sentiment_gold        40 non-null     object \n",
            " 7   name                          14640 non-null  object \n",
            " 8   negativereason_gold           32 non-null     object \n",
            " 9   retweet_count                 14640 non-null  int64  \n",
            " 10  text                          14640 non-null  object \n",
            " 11  tweet_coord                   1019 non-null   object \n",
            " 12  tweet_created                 14640 non-null  object \n",
            " 13  tweet_location                9907 non-null   object \n",
            " 14  user_timezone                 9820 non-null   object \n",
            "dtypes: float64(2), int64(2), object(11)\n",
            "memory usage: 1.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NIAc7kSE7N5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "598006ad-1750-42b9-bf30-2026f4d5668c"
      },
      "source": [
        "# then we gaze upon her variables\n",
        "nuniques = pd.DataFrame(columns=[\"Column Name\", \"Uniques #\"])\n",
        "for i in tweets.columns:\n",
        "    nuniques = nuniques.append({\"Column Name\":i, \"Uniques #\":tweets[i].nunique()}, \n",
        "                                           ignore_index=True)\n",
        "display(nuniques)\n",
        "del(nuniques)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column Name</th>\n",
              "      <th>Uniques #</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet_id</td>\n",
              "      <td>14485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>airline_sentiment</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>airline_sentiment_confidence</td>\n",
              "      <td>1023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negativereason</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negativereason_confidence</td>\n",
              "      <td>1410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>airline</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>airline_sentiment_gold</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>name</td>\n",
              "      <td>7701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>negativereason_gold</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>retweet_count</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>text</td>\n",
              "      <td>14427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>tweet_coord</td>\n",
              "      <td>832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tweet_created</td>\n",
              "      <td>14247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tweet_location</td>\n",
              "      <td>3081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>user_timezone</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Column Name Uniques #\n",
              "0                       tweet_id     14485\n",
              "1              airline_sentiment         3\n",
              "2   airline_sentiment_confidence      1023\n",
              "3                 negativereason        10\n",
              "4      negativereason_confidence      1410\n",
              "5                        airline         6\n",
              "6         airline_sentiment_gold         3\n",
              "7                           name      7701\n",
              "8            negativereason_gold        13\n",
              "9                  retweet_count        18\n",
              "10                          text     14427\n",
              "11                   tweet_coord       832\n",
              "12                 tweet_created     14247\n",
              "13                tweet_location      3081\n",
              "14                 user_timezone        85"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV2F25DMcuWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "58b72329-b06b-4785-ca7e-38b99ced819c"
      },
      "source": [
        "# ...and she takes off her fancy fur coat and some other unnecessary ornaments \n",
        "tweets.drop(columns=[\"tweet_id\", \"airline_sentiment_gold\", \"name\", \n",
        "                     \"negativereason_gold\", \"retweet_count\", \"tweet_created\", \n",
        "                     \"tweet_coord\", \"tweet_created\", \"tweet_location\", \n",
        "                     \"user_timezone\"], \n",
        "            inplace=True\n",
        "            )\n",
        "tweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment  ...                                               text\n",
              "0           neutral  ...                @VirginAmerica What @dhepburn said.\n",
              "1          positive  ...  @VirginAmerica plus you've added commercials t...\n",
              "2           neutral  ...  @VirginAmerica I didn't today... Must mean I n...\n",
              "3          negative  ...  @VirginAmerica it's really aggressive to blast...\n",
              "4          negative  ...  @VirginAmerica and it's a really big bad thing...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsA1U4aNlHhY",
        "colab_type": "text"
      },
      "source": [
        "# 1 - Cleaning the dance area!\n",
        "\n",
        "We are going to clean the tweets to only English words by removing:\n",
        "\n",
        "* Symbols\n",
        "* Numbers\n",
        "* The airline brands (since we already have the corresponding column)\n",
        "\n",
        "Now we need to find the Twitter account names of the airlines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZC7F27ZwxCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2260e7b9-674e-460e-b852-59703d066278"
      },
      "source": [
        "import re, string, nltk\n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m--5joyBoq4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93ad036b-88b3-444a-f7dc-c4338fa204c8"
      },
      "source": [
        "# Airline companies:\n",
        "list(tweets.airline.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Virgin America', 'United', 'Southwest', 'Delta', 'US Airways', 'American']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R6fz2j-pLvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eff59996-1b89-45ac-bec5-cdba99a5a38f"
      },
      "source": [
        "# The twitter accounts mentioned:\n",
        "set_them = set()\n",
        "for i in tweets.text:\n",
        "    search_them = re.search(r\"(^|[^@\\w])@(\\w{1,15})\\b\", i)\n",
        "    give_them = search_them.group().lower()\n",
        "    set_them.add(give_them)\n",
        "\n",
        "print(set_them)\n",
        "del set_them"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n@jetblue', ' @southwestair', '@usairways', ',@usairways', '@vanessaannz', '“@virginamerica', '“@united', '\"@jetblue', '@shannonwoodward', ' @virginamerica', '@nrhodes85', '.@americanair', '“@americanair', '@deltaassist', '@americanair', '@timbennettg3', '“@jetblue', '\"@united', ' @chasefoster', '@hillaconlin', ' @nytimes', '@djevolutionhd', ' @united', '@malhoit', '@ninadavuluri', '@jetblue', ' @dadboner', '@united', ' @usairways', ' @melissaafrancis', '@sarahpompei', '@sb5551', ' @mandarinjourney', '“@usairways', '.@jetblue', '@eatgregeat', ' @kciairport', '.@virginamerica', ';@southwestair', '@virginamerica', '.@usairways', '@lindaswc', ' @americanair', '@catfoodbeerglue', '.@southwestair', '@southwestair', '@albertbreer', '.@united', ' @jetblue', ' @internjohnradio', '@andrewfallis', '@ods1819', ' @imaginedragons', '“@southwestair', '@scm1133'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFvcS0KmyFer",
        "colab_type": "text"
      },
      "source": [
        "These are the Twitter accounts we will remove:\n",
        "* @virginamerica\n",
        "* @united\n",
        "* @southwestair\n",
        "* @deltaassist\n",
        "* @usairways\n",
        "* @americanair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cW5XMfnlUP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tweet_cleaner(tweet):\n",
        "    \"Symbols, numbers & airline brand cleaner function!\"\n",
        "    # First step: Symbols and numbers are gone:\n",
        "    cleaned_string = re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
        "\n",
        "    # Party people here speak only English. No other languages are allowed:\n",
        "    cleaned_string = \" \".join(w for w in nltk.wordpunct_tokenize(cleaned_string) \\\n",
        "         if w.lower() in words)\n",
        "\n",
        "    # Second step: Putting them to a list:\n",
        "    cleaned_set = set(cleaned_string.lower().split())\n",
        "    # Let's get rid of our meaningless one-letter friends: \n",
        "    what_to_clean = list(string.ascii_lowercase)\n",
        "    # ...and some of their drunk buddies:\n",
        "    what_to_clean.extend([\"it\", \"of\", \"co\", \"to\", \"http\"])\n",
        "    # We don't need any officials in our party as well:\n",
        "    what_to_clean.extend([\"virginamerica\", \"united\", \n",
        "                       \"southwestair\", \"deltaassist\",\n",
        "                       \"usairways\", \"americanair\"])\n",
        "    for delete in what_to_clean:\n",
        "        try:\n",
        "            cleaned_set.remove(delete)\n",
        "        except:\n",
        "            continue    \n",
        "    return list(cleaned_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuGqFKLx-3vv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8d87591a-d5c6-44f9-dd0a-9740e42e93f6"
      },
      "source": [
        "# let's test the function we prepared for the party drinkers:\n",
        "# example 1\n",
        "print(\"Original tweet:\\n\", tweets.loc[100, \"text\"], \"\\n\")\n",
        "print(\"Cleaned and listed tweet:\\n\", tweet_cleaner(tweets.loc[100, \"text\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tweet:\n",
            " @VirginAmerica trying to add my boy Prince to my ressie. SF this Thursday @VirginAmerica from LAX http://t.co/GsB2J3c4gM \n",
            "\n",
            "Cleaned and listed tweet:\n",
            " ['add', 'from', 'this', 'my', 'trying', 'lax', 'prince', 'boy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DrhmkdOXzfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f6f3c1a2-b991-4c75-a7f5-45b22db94545"
      },
      "source": [
        "# example 2\n",
        "print(\"Original tweet:\\n\", tweets.loc[2000, \"text\"], \"\\n\")\n",
        "print(\"Cleaned and listed tweet:\\n\", tweet_cleaner(tweets.loc[2000, \"text\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tweet:\n",
            " @united wifi wasn't working onboard.Alerted attendant re socket.You sent me to a hotel for 24 hours with 7$ Vouchers??no wifi at hotel \n",
            "\n",
            "Cleaned and listed tweet:\n",
            " ['no', 'you', 'working', 'me', 'hotel', 'for', 'socket', 'sent', 'attendant', 'at', 'with', 're']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8l4oEIMDubI",
        "colab_type": "text"
      },
      "source": [
        "Good enough!<br>And one last thing:\n",
        "We need to convert the \"airline_sentiment\" values to numbers to work on them easier. Here is what it's gonna be:\n",
        "\n",
        "* \"Neutral\" sentiment becomes: 0\n",
        "* \"Positive\" sentiment becomes: 1\n",
        "* \"Negative\" sentiment becomes: 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS5jD2AaEZrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d8f5db58-1732-4537-99bf-2c935c8bc262"
      },
      "source": [
        "print(\"Before:\\n'Airline Sentiment' unique values:\", tweets.airline_sentiment.unique())\n",
        "for i,j in enumerate(tweets.airline_sentiment.unique()):\n",
        "    tweets.airline_sentiment = tweets.airline_sentiment.replace(j, i)\n",
        "tweets.airline_sentiment.astype(\"int64\")\n",
        "print(\"After:\\n'Airline Sentiment' unique values:\", tweets.airline_sentiment.unique())\n",
        "# homework: please see the module ---> \"sklearn.preprocessing.LabelEncoder().fit_transform(?)\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before:\n",
            "'Airline Sentiment' unique values: ['neutral' 'positive' 'negative']\n",
            "After:\n",
            "'Airline Sentiment' unique values: [0 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKs2wohtSqRE",
        "colab_type": "text"
      },
      "source": [
        "# 2 - Let the party begin!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UkbxYSUUsS4",
        "colab_type": "text"
      },
      "source": [
        "We are going to collect all the words and give them binary inputs (1 or 0) according to their entities in the tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW0ZzRsaRscD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ecf53f9-083e-4cd0-88f2-91c160493c25"
      },
      "source": [
        "all_words = set()\n",
        "rows=[] ### Tweetleri daha sonra aşağıda liste olarak kullanabilmek için\n",
        "for i in tweets.index:\n",
        "    listed_tweet = tweet_cleaner(tweets.text[i]) ### Aynı şeyi iki kez hesaplamamak için\n",
        "    rows.append(listed_tweet) ### Tweetleri daha sonra aşağıda liste olarak kullanabilmek için\n",
        "    all_words.update(listed_tweet) ### .add() yerine listeler için .update() kullanılabilir\n",
        "print(\"Total number of distinct words:\", len(all_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of distinct words: 5361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keOhFV0Xdis0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1f839dc5-84bd-4cea-f000-c8886c5fa099"
      },
      "source": [
        "%%time\n",
        "### Öncelikle, içi sıfırlarla dolu, sütun adları kelimeler olan ve\n",
        "### indeksi tweet DF'nin indeksine eşit olan bir DF oluşturduk.\n",
        "### Daha sonra satırları dolaşarak, satırlardaki kelimeleri içeren\n",
        "### sütunların değerini değiştiriyoruz.\n",
        "\n",
        "df_words = pd.DataFrame(0, columns=all_words, index=tweets.index)\n",
        "\n",
        "for i in tweets.index:\n",
        "    df_words.loc[i, rows[i]]=1\n",
        "\n",
        "\"\"\"\n",
        "df_words = pd.DataFrame()\n",
        "for i in tweets.index:\n",
        "    for j in all_words:\n",
        "        condition = int(j in tweet_cleaner(tweets.loc[i, \"text\"]))\n",
        "        df_words = df_words.append({j:condition}, ignore_index=True)\n",
        "\"\"\"\n",
        "### İç içe döngüler, kodların zaman karmaşıklığını inanılmaz derecede artırır.\n",
        "### Şu anda olduğu gibi çok fazla satır ve sütun olduğunda gördüğümüz gibi işimiz oldukça uzun sürer.\n",
        "### Benim yazdığım kod (satır bazında dolaşırken), benim bilgisayarımda 40,7sn sürdü.\n",
        "### Bu durumda siz sütünları da dolaştığınıza göre, sizin kodunuzun tamamlanması\n",
        "###      yine benim bilgisayarımda yaklaşık olarak (40,7 x 13624 = 554.497 sn) 6,4 gün sürer.\n",
        "### Aradaki fark ilginç değil mi? :)\n",
        "### Mümkün olduğunca iç içe döngülerden kaçınalım :)\n",
        "print(\"The commented out code took tremendous amount of time. So it's reduced.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The commented out code took tremendous amount of time. So it's reduced.\n",
            "CPU times: user 8.89 s, sys: 306 ms, total: 9.2 s\n",
            "Wall time: 9.21 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtWAoqLj9P2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# it's time to concatenate the data frames\n",
        "tweets = pd.concat([tweets, df_words], ignore_index=False, axis=\"columns\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-YdctUoARtx",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 - Logistic Regression Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67HhTIDN8oFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "\n",
        "X = tweets.iloc[:, 6:]\n",
        "Y = tweets.airline_sentiment\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgmLyBoK63eQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "88b31c7b-025c-4c81-84c6-65c2877d8216"
      },
      "source": [
        "%%time\n",
        "lr_model1 = LogisticRegression(C=0.1, solver=\"lbfgs\", max_iter=300, n_jobs=-1)\n",
        "lr_model1.fit(x_train, y_train)\n",
        "train_score_model1 = lr_model1.score(x_train, y_train)\n",
        "test_score_model1 = lr_model1.score(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.37 s, sys: 538 ms, total: 1.91 s\n",
            "Wall time: 38.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pMYPUegnMMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "db8d47f1-bb82-4f36-f223-225517928983"
      },
      "source": [
        "print(\"Model-1\\nTrain score with 'lbfgs' solver: {:.3f}\".format(train_score_model1))\n",
        "print(\"Test score with 'lbfgs' solver: {:.3f}\".format(test_score_model1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model-1\n",
            "Train score with 'lbfgs' solver: 0.824\n",
            "Test score with 'lbfgs' solver: 0.789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mxdCNlck5HM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6612bd7c-1f15-45de-e7a5-0946b4d7a9f7"
      },
      "source": [
        "%%time\n",
        "lr_model2 = LogisticRegression(C=0.1, solver=\"liblinear\", max_iter=300)\n",
        "lr_model2.fit(x_train, y_train)\n",
        "train_score_model2 = lr_model2.score(x_train, y_train)\n",
        "test_score_model2 = lr_model2.score(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.66 s, sys: 127 ms, total: 1.79 s\n",
            "Wall time: 1.49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWTFnD4Wnb7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1ec3a9e5-cc32-4743-b64b-0a5a220d6540"
      },
      "source": [
        "print(\"Model-2\\nTrain score with 'liblinear' solver: {:.3f}\".format(train_score_model2))\n",
        "print(\"Test score with 'liblinear' solver: {:.3f}\".format(test_score_model2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model-2\n",
            "Train score with 'liblinear' solver: 0.807\n",
            "Test score with 'liblinear' solver: 0.781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLadlEdzq0j_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 1 predictions:\n",
        "train_predict_model1 = lr_model1.predict(x_train)\n",
        "test_predict_model1 = lr_model1.predict(x_test)\n",
        "predict_prob_model1 = lr_model1.predict_proba(x_test)[:, 1] # predict probability \n",
        "# model 2 predictions:\n",
        "train_predict_model2 = lr_model2.predict(x_train)\n",
        "test_predict_model2 = lr_model2.predict(x_test)\n",
        "predict_prob_model2 = lr_model2.predict_proba(x_test)[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF_GTdAYf7zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You know we need to check how we did. Confusion matrix will help.\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "#from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Model-1:\n",
        "cm_train_model1 = confusion_matrix(y_train, train_predict_model1, \n",
        "                                   labels=[0, 1, 2])\n",
        "cm_test_model1 = confusion_matrix(y_test, test_predict_model1, \n",
        "                                  labels=[0, 1, 2])\n",
        "f1_score_model1 = f1_score(y_true=y_test, y_pred=test_predict_model1, \n",
        "                           average=\"weighted\")    ## average= kısmını dokümandan okudum fakat tam anlamadım.\n",
        "accuracy_score_model1 = accuracy_score(y_test, test_predict_model1)\n",
        "#log_loss_model1 = log_loss(y_test, predict_prob_model1, labels=[0, 1, 2])\n",
        "## HATA: ValueError: The number of classes in labels is different from that in y_pred. Classes found in labels: [0 1 2]\n",
        "\n",
        "# Model-2:\n",
        "cm_train_model2 = confusion_matrix(y_train, train_predict_model2, \n",
        "                                   labels=[0, 1, 2])\n",
        "cm_test_model2 = confusion_matrix(y_test, test_predict_model2, \n",
        "                                  labels=[0, 1, 2])\n",
        "f1_score_model2 = f1_score(y_true=y_test, y_pred=test_predict_model2, \n",
        "                           average=\"weighted\")\n",
        "accuracy_score_model2 = accuracy_score(y_test, test_predict_model2)\n",
        "##log_loss_model2 = log_loss(y_test, predict_prob_model2, labels=[0, 1, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV2RJ4H00XBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "a2f8843b-79cd-4543-8fad-383cca67116d"
      },
      "source": [
        "# Model-1:\n",
        "print(\"MODEL-1:\\nConfusion Matrix (Train Set)\", \"-\"*30, cm_train_model1, sep=\"\\n\")\n",
        "print(\"\\nConfusion Matrix (Test Set)\", \"-\"*30, cm_test_model1, sep=\"\\n\")\n",
        "print(f\"\\nwith f1-score: {f1_score_model1:.3f}\")\n",
        "print(f\"Accuracy score: {accuracy_score_model1:.3f}\")\n",
        "print(f\"Error score: {(1-accuracy_score_model1):.3f}\")\n",
        "#print(f\"Logarithmic Loss: {log_loss_model1:.3f}\")\n",
        "print(\"\\n\",\"*\"*30, sep=\"\")\n",
        "# Model-2:\n",
        "print(\"\\nMODEL-2:\\nConfusion Matrix (Train Set)\", \"-\"*30, cm_train_model2, sep=\"\\n\")\n",
        "print(\"Confusion Matrix (Test Set)\", \"-\"*30, cm_test_model2, sep=\"\\n\")\n",
        "print(f\"with f1-score: {f1_score_model2:.3f}\")\n",
        "print(f\"Accuracy score: {accuracy_score_model2:.3f}\")\n",
        "print(f\"Error score: {(1-accuracy_score_model2):.3f}\")\n",
        "#print(f\"Logarithmic Loss: {log_loss_model2:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL-1:\n",
            "Confusion Matrix (Train Set)\n",
            "------------------------------\n",
            "[[1583  132  804]\n",
            " [ 226 1255  423]\n",
            " [ 360  121 6808]]\n",
            "\n",
            "Confusion Matrix (Test Set)\n",
            "------------------------------\n",
            "[[ 315   45  220]\n",
            " [  60  285  114]\n",
            " [ 125   54 1710]]\n",
            "\n",
            "with f1-score: 0.783\n",
            "Accuracy score: 0.789\n",
            "Error score: 0.211\n",
            "\n",
            "******************************\n",
            "\n",
            "MODEL-2:\n",
            "Confusion Matrix (Train Set)\n",
            "------------------------------\n",
            "[[1415  140  964]\n",
            " [ 225 1189  490]\n",
            " [ 319  122 6848]]\n",
            "Confusion Matrix (Test Set)\n",
            "------------------------------\n",
            "[[ 293   40  247]\n",
            " [  61  268  130]\n",
            " [ 114   49 1726]]\n",
            "with f1-score: 0.772\n",
            "Accuracy score: 0.781\n",
            "Error score: 0.219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7o5lmIZ11aF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "19fe8637-7604-4e75-df01-94c481777a0f"
      },
      "source": [
        "print(\"Classification Report for Model-1:\\n\", classification_report(y_test, test_predict_model1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Model-1:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.54      0.58       580\n",
            "           1       0.74      0.62      0.68       459\n",
            "           2       0.84      0.91      0.87      1889\n",
            "\n",
            "    accuracy                           0.79      2928\n",
            "   macro avg       0.74      0.69      0.71      2928\n",
            "weighted avg       0.78      0.79      0.78      2928\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F9xnjKm5eYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "17ec547a-7742-4ea2-f70f-89196984c4db"
      },
      "source": [
        "print(\"Classification Report for Model-2:\\n\", classification_report(y_test, test_predict_model2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Model-2:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.51      0.56       580\n",
            "           1       0.75      0.58      0.66       459\n",
            "           2       0.82      0.91      0.86      1889\n",
            "\n",
            "    accuracy                           0.78      2928\n",
            "   macro avg       0.73      0.67      0.69      2928\n",
            "weighted avg       0.77      0.78      0.77      2928\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saqI0msOAYfz",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 - Naive Bayes Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOx4AbigAdkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YgwxM3XqsXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "179d99e6-5994-4ccb-bdd9-fe1e0d58aa7d"
      },
      "source": [
        "%%time\n",
        "naive = MultinomialNB()\n",
        "parameters = {\"alpha\":np.logspace(-5,5,100), \"fit_prior\":[True, False]}\n",
        "grid_cv = GridSearchCV(estimator=naive, param_grid=parameters, cv=10)\n",
        "grid_cv.fit(x_train, y_train)\n",
        "print(\"Best parameters : \", grid_cv.best_params_)\n",
        "print(\"Best scores     : \", grid_cv.best_score_, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters :  {'alpha': 1.7886495290574351, 'fit_prior': False}\n",
            "Best scores     :  0.7581099553195396 \n",
            "\n",
            "CPU times: user 16min 36s, sys: 3min 21s, total: 19min 57s\n",
            "Wall time: 15min 42s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Joof_6ttT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "aef6ef2a-f667-4e0f-b89d-3d240a396712"
      },
      "source": [
        "results = pd.DataFrame(grid_cv.cv_results_)\n",
        "results = results[[\"param_alpha\", \"param_fit_prior\", \"mean_test_score\"]]\n",
        "results = results.sort_values(by=\"mean_test_score\", ascending=False)\n",
        "results.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>param_fit_prior</th>\n",
              "      <th>mean_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>1.78865</td>\n",
              "      <td>False</td>\n",
              "      <td>0.758110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>1.41747</td>\n",
              "      <td>False</td>\n",
              "      <td>0.756830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>1.12332</td>\n",
              "      <td>False</td>\n",
              "      <td>0.755294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>2.25702</td>\n",
              "      <td>False</td>\n",
              "      <td>0.753585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.559081</td>\n",
              "      <td>True</td>\n",
              "      <td>0.751878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.70548</td>\n",
              "      <td>True</td>\n",
              "      <td>0.751451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.443062</td>\n",
              "      <td>True</td>\n",
              "      <td>0.751451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.890215</td>\n",
              "      <td>True</td>\n",
              "      <td>0.751195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>0.351119</td>\n",
              "      <td>True</td>\n",
              "      <td>0.750853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1.12332</td>\n",
              "      <td>True</td>\n",
              "      <td>0.750427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    param_alpha param_fit_prior  mean_test_score\n",
              "105     1.78865           False         0.758110\n",
              "103     1.41747           False         0.756830\n",
              "101     1.12332           False         0.755294\n",
              "107     2.25702           False         0.753585\n",
              "94     0.559081            True         0.751878\n",
              "96      0.70548            True         0.751451\n",
              "92     0.443062            True         0.751451\n",
              "98     0.890215            True         0.751195\n",
              "90     0.351119            True         0.750853\n",
              "100     1.12332            True         0.750427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SjzmOARyZW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "487790e1-1841-4265-b46a-02d934cccfd1"
      },
      "source": [
        "best_alpha = grid_cv.cv_results_[\"param_alpha\"][105]\n",
        "naive2 = MultinomialNB(alpha=best_alpha, fit_prior=False)\n",
        "naive2.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.7886495290574351, class_prior=None, fit_prior=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpL2DksvzL-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8cc1ebc-f31b-4277-8248-93aebef4fc5b"
      },
      "source": [
        "print(\"Test score:\", naive2.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.7793715846994536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZQ1u-zlzouQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fd72f06-98e7-4fa0-a270-fe655a05b8e9"
      },
      "source": [
        "naive3 = GaussianNB()\n",
        "naive3.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMnOgb680Gi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "211dc736-168a-480e-9244-f4415a585127"
      },
      "source": [
        "print(\"Test score:\", naive3.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.3948087431693989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQvn3ll9XSBa",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "---\n",
        "# Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecCtgIrLWfYN",
        "colab_type": "text"
      },
      "source": [
        "**To do list:**\n",
        "\n",
        "1. Tüm kelimeler kümelenerek DataFrame'e eklenecek.\n",
        "2. Her bir index'e göre binary şekilde işaretlenecek.\n",
        "3. Logistic regression modeli kurulacak.\n",
        "    * Naive Bayes denenebilir.\n",
        "4. Parametre ayarları yapılıp başarılı bir noktaya gelinecek.\n",
        "5. Ardından şu iki seçenek denenerek model yeniden geliştirilecek.\n",
        "    * \"airline_sentiment_confidence\" ve/veya \"negativereason_confidence\" değerleri belli bir değerden düşük olan (örn: 0.1 veya 0.2) datalar veri setinden çıkarılarak performansın değişimine bakılacak.\n",
        "    * \"tweet_cleaner\" fonksiyonunda pasifleştirilen, İngilizce sözcükleri süzen satırlar aktifleştirilerek performansın değişimine bakılacak.\n",
        "6. En başarılı model seçilerek partiye devam edilecek.\n"
      ]
    }
  ]
}
